define({ entries : {
    "BarehChanlangKi2025Aqao": {
        "author": "Bareh, Chanlang Ki",
        "issn": "2730-5953",
        "journal": "Ai and ethics (Online)",
        "language": "eng",
        "title": "A qualitative assessment of the accuracy of AI-LLM in academic research",
        "type": "article",
        "year": "2025"
    },
    "Beck2016Visual": {
        "abstract": "Bibiographic data such as collections of scientific articles and citation networks have been studied extensively in information visualization and visual analytics research. Powerful systems have been built to support various types of bibliographic analysis, but they require some training and cannot be used to disseminate the insights gained. In contrast, we focused on developing a more accessible visual analytics system, called SurVis, that is ready to disseminate a carefully surveyed literature collection. The authors of a survey may use our Web-based system to structure and analyze their literature database. Later, readers of the survey can obtain an overview, quickly retrieve specific publications, and reproduce or extend the original bibliographic analysis. Our system employs a set of selectors that enable users to filter and browse the literature collection as well as to control interactive visualizations. The versatile selector concept includes selectors for textual search, filtering by keywords and meta-information, selection and clustering of similar publications, and following citation links. Agreement to the selector is represented by word-sized sparkline visualizations seamlessly integrated into the user interface. Based on an analysis of the analytical reasoning process, we derived requirements for the system. We developed the system in a formative way involving other researchers writing literature surveys. A questionnaire study with 14 visual analytics experts confirms that SurVis meets the initially formulated requirements.",
        "author": "Beck, Fabian and Koch, Sebastian and Weiskopf, Daniel",
        "doi": "10.1109/TVCG.2015.2467757",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "keywords": "type:system, visual_analytics, sparklines, information_retrieval, clustering, literature_browser",
        "number": "01",
        "publisher": "IEEE",
        "series": "TVCG",
        "title": "Visual Analysis and Dissemination of Scientific Literature Collections with {SurVis}",
        "type": "article",
        "url": "http://www.visus.uni-stuttgart.de/uploads/tx_vispublications/vast15-survis.pdf",
        "volume": "22",
        "year": "2016"
    },
    "Castellanos-ReyesDaniela2025Tolr": {
        "abstract": "The last two decades of online learning research vastly flourished by examining discussion board text data through content analysis based on constructs like cognitive presence (CP) with the Practical Inquiry Model (PIM). The PIM sets a footprint for how cognitive development unfolds in collaborative inquiry in online learning experiences. Ironically, content analysis is a resource-intensive endeavor in terms of time and expertise, making researchers look for ways to automate text classification through ensemble machine-learning algorithms. We leveraged large language models (LLMs) through OpenAI's Generative Pre-Trained Transformer (GPT) models in the public API to automate the content analysis of students' text data based on PIM indicators and assess the reliability and efficiency of automated content analysis compared to human analysis. Using the seven steps of the Large Language Model Content Analysis (LACA) approach, we proposed an AI-adapted CP codebook leveraging prompt engineering techniques (i.e., role, chain-of-thought, one-shot, few-shot) for the automated content analysis of CP. We found that a fine-tuned model with a one-shot prompt achieved moderate interrater reliability with researchers. The models were more reliable when classifying students' discussion board text in the Integration phase of the PIM. A cost comparison showed an obvious cost advantage of LACA approaches in online learning research in terms of efficiency. Nevertheless, practitioners still need considerable data literacy skills to deploy LACA at a scale. We offer theoretical suggestions for simplifying the CP codebook and improving the IRR with LLM. Implications for practice are discussed, and future research that includes instructional advice is recommended. \u2022A simplified AI-adapted CP codebook enhances Large Language Model Content Analysis.\u2022A fine-tuned model with a one-shot prompt achieved a moderate to substantial IRR.\u2022LLMs performed better in the automated content analysis of CP's integration phase.\u2022Large Language Model Content Analysis optimizes research of online discussion data.\u2022LACA is low-cost in online learning research, but escalation needs data literacy.",
        "author": "Castellanos-Reyes, Daniela and Olesova, Larisa and Sadaf, Ayesha",
        "copyright": "2025",
        "issn": "1096-7516",
        "journal": "The Internet and higher education",
        "keywords": "Large language models ; Artificial intelligence in education ; Automated content analysis ; Cognitive presence ; Discussion boards ; GPT ; Online learning",
        "language": "eng",
        "pages": "101001-",
        "publisher": "Elsevier Inc",
        "title": "Transforming online learning research: Leveraging GPT large language models for automated content analysis of cognitive presence",
        "type": "article",
        "volume": "65",
        "year": "2025"
    },
    "KortschotSeanW.2022DaRt": {
        "abstract": "Objective The objective of this study was to develop and evaluate an adaptive user interface that could detect states of operator information overload and calibrate the amount of information on the screen. Background Machine learning can detect changes in operating context and trigger adaptive user interfaces (AUIs) to accommodate those changes. Operator attentional state represents a promising aspect of operating context for triggering AUIs. Behavioral rather than physiological indices can be used to infer operator attentional state. Method In Experiment 1, a network analysis task sought to induce states of information overload relative to a baseline. Streams of interaction data were taken from these two states and used to train machine learning classifiers. We implemented these classifiers in Experiment 2 to drive an AUI that automatically calibrated the amount of information displayed to operators. Results Experiment 1 successfully induced information overload in participants, resulting in lower accuracy, slower completion time, and higher workload. A series of machine learning classifiers detected states of information overload significantly above chance level. Experiment 2 identified four clusters of users who responded significantly differently to the AUIs. The AUIs benefited performance, completion time, and workload in three clusters. Conclusion Behavioral indices can successfully detect states of information overload and be used to effectively drive an AUI for some user groups. The success of AUIs may be contingent on characteristics of the user group. Application This research applies to domains seeking real-time assessments of user attentional or psychological state.",
        "address": "Los Angeles, CA",
        "author": "Kortschot, Sean W. and Jamieson, Greg A. and Prasad, Amrit",
        "copyright": "Copyright \u00a9 2020, Human Factors and Ergonomics Society",
        "issn": "0018-7208",
        "journal": "Human factors",
        "keywords": "Ergonomics ; information overload ; adaptive automation ; attentional processes ; Behavioral Sciences ; Change detection ; Classifiers ; Clusters ; Completion time ; Context ; Engineering ; Engineering Industrial ; Experiments ; Interfaces ; Learning algorithms ; Life Sciences & Biomedicine ; Machine learning ; Network analysis ; Overloading ; passive data monitoring ; Psychology ; Psychology Applied ; Science & Technology ; Social Sciences ; Technology ; User groups ; User interface ; User interfaces ; Workload ; Workloads",
        "language": "eng",
        "number": "4",
        "pages": "675-693",
        "publisher": "SAGE Publications",
        "title": "Detecting and Responding to Information Overload With an Adaptive User Interface",
        "type": "article",
        "volume": "64",
        "year": "2022"
    },
    "KumarHarsh2024GSiU": {
        "abstract": "Personalized chatbot-based teaching assistants can be crucial in addressing increasing classroom sizes, especially where direct teacher presence is limited. Large language models (LLMs) offer a promising avenue, with increasing research exploring their educational utility. However, the challenge lies not only in establishing the efficacy of LLMs but also in discerning the nuances of interaction between learners and these models, which impact learners' engagement and results. We conducted a formative study in an undergraduate computer science classroom (N",
        "address": "New York, NY, USA",
        "author": "Kumar, Harsh and Musabirov, Ilya and Reza, Mohi and Shi, Jiakai and Wang, Xinyuan and Williams, Joseph Jay and Kuzminykh, Anastasia and Liut, Michael",
        "copyright": "ACM",
        "issn": "2573-0142",
        "journal": "Proceedings of the ACM on human-computer interaction",
        "keywords": "Human computer interaction (HCI) ; Applied computing ; artificial intelligence in education ; collaborative learning with ai ; Collaborative and social computing ; Computer-assisted instruction ; Computing education ; Education ; Empirical studies in collaborative and social computing ; Empirical studies in HCI ; human-ai collaboration ; Human-centered computing ; large language models ; Professional topics ; Social and professional topics ; transparency ; tutoring systems",
        "language": "eng",
        "number": "CSCW2",
        "pages": "1-30",
        "publisher": "ACM",
        "title": "Guiding Students in Using LLMs in Supported Learning Environments: Effects on Interaction Dynamics, Learner Performance, Confidence, and Trust",
        "type": "article",
        "volume": "8",
        "year": "2024"
    },
    "LiXuhong2022Idli": {
        "abstract": "Deep neural networks have been well-known for their superb handling of various machine learning and artificial intelligence tasks. However, due to their over-parameterized black-box nature, it is often difficult to understand the prediction results of deep models. In recent years, many interpretation tools have been proposed to explain or reveal how deep models make decisions. In this paper, we review this line of research and try to make a comprehensive survey. Specifically, we first introduce and clarify two basic concepts\u2014interpretations and interpretability\u2014that people usually get confused about. To address the research efforts in interpretations, we elaborate the designs of a number of interpretation algorithms, from different perspectives, by proposing a new taxonomy. Then, to understand the interpretation results, we also survey the performance metrics for evaluating interpretation algorithms. Further, we summarize the current works in evaluating models\u2019 interpretability using \u201ctrustworthy\u201d interpretation algorithms. Finally, we review and discuss the connections between deep models\u2019 interpretations and other factors, such as adversarial robustness and learning from interpretations, and we introduce several open-source libraries for interpretation algorithms and evaluation approaches.",
        "address": "London",
        "author": "Li, Xuhong and Xiong, Haoyi and Li, Xingjian and Wu, Xuanyu and Zhang, Xiao and Liu, Ji and Bian, Jiang and Dou, Dejing",
        "copyright": "The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature 2022. Springer Nature or its licensor holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law.",
        "issn": "0219-1377",
        "journal": "Knowledge and information systems",
        "keywords": "Deep learning ; Information Systems Applications (incl.Internet) ; Interpretable deep learning ; Algorithms ; Artificial intelligence ; Artificial neural networks ; Computer Science ; Computer Science Information Systems ; Computer Science Artificial Intelligence ; Data Mining and Knowledge Discovery ; Database Management ; Information Storage and Retrieval ; Information Systems and Communication Service ; Interpretability ; Interpretation ; IT in Business ; Machine learning ; Performance evaluation ; Performance measurement ; Science & Technology ; Survey Paper ; Taxonomy ; Technology ; Trustworthiness",
        "language": "eng",
        "number": "12",
        "pages": "3197-3234",
        "publisher": "Springer London",
        "title": "Interpretable deep learning: interpretation, interpretability, trustworthiness, and beyond",
        "type": "article",
        "volume": "64",
        "year": "2022"
    },
    "McNuttMarciaK.2018Tiac": {
        "abstract": "In keeping with the growing movement in scientific publishing toward transparency in data and methods, we propose changes to journal authorship policies and procedures to provide insight into which author is responsible for which contributions, better assurance that the list is complete, and clearly articulated standards to justify earning authorship credit. To accomplish these goals, we recommend that journals adopt common and transparent standards for authorship, outline responsibilities for corresponding authors, adopt the Contributor Roles Taxonomy (CRediT) (docs.casrai.org/CRediT) methodology for attributing contributions, include this information in article metadata, and require authors to use the ORCID persistent digital identifier (https://orcid.org). Additionally, we recommend that universities and research institutions articulate expectations about author roles and responsibilities to provide a point of common understanding for discussion of authorship across research teams. Furthermore, we propose that funding agencies adopt the ORCID identifier and accept the CRediT taxonomy. We encourage scientific societies to further authorship transparency by signing on to these recommendations and promoting them through their meetings and publications programs.",
        "address": "WASHINGTON",
        "author": "McNutt, Marcia K. and Bradford, Monica and Drazen, Jeffrey M. and Hanson, Brooks and Howard, Bob and Jamieson, Kathleen Hall and Kiermer, V\u00e9ronique and Marcus, Emilie and Pope, Barbara Kline and Schekman, Randy and Swaminathan, Sowmya and Stang, Peter J. and Verma, Inder M.",
        "copyright": "Volumes 1\u201389 and 106\u2013114, copyright as a collective work only; author(s) retains copyright to individual articles",
        "issn": "0027-8424",
        "journal": "Proceedings of the National Academy of Sciences - PNAS",
        "keywords": "Science & Technology - Other Topics ; Scientific integrity ; Transparency ; Academic publications ; Authoring ; Authorship ; Authorship principles ; Colleges & universities ; Multidisciplinary Sciences ; PERSPECTIVE ; R&D ; Research & development ; Research institutions ; Research transparency ; Scholarly publishing ; Science & Technology ; Social Sciences ; Taxonomy",
        "language": "eng",
        "number": "11",
        "pages": "2557-2560",
        "publisher": "National Academy of Sciences",
        "title": "Transparency in authors\u2019 contributions and responsibilities to promote integrity in scientific publication",
        "type": "article",
        "volume": "115",
        "year": "2018"
    },
    "NichaniPremA.H.2025UoOL": {
        "abstract": "Supplemental Digital Content is Available in the Text.This is the first study to illustrate the comparative efficacy and strong potential that large language models have to streamline high volume cornea clinics by assisting with patient counselling, administrative tasks, and research strategy development. Purpose:Online large language model (LLM) chatbots have garnered attention for their potential in enhancing efficiency, providing education, and advancing research. This study evaluated the performance of LLM chatbots-Chat Generative Pre-Trained Transformer (ChatGPT), Writesonic, Google Bard, and Bing Chat-in responding to cornea-related scenarios.Methods:Prompts covering clinic administration, patient counselling, treatment algorithms, surgical management, and research were devised. Responses from LLMs were assessed by 3 fellowship-trained cornea specialists, blinded to the LLM used, using a standardized rubric evaluating accuracy, comprehension, compassion, professionalism, humanness, comprehensiveness, and overall quality. In addition, 12 readability metrics were used to further evaluate responses. Scores were averaged and ranked; subgroup analyses were performed to identify the best-performing LLM for each rubric criterion.Results:Sixty-six responses were generated from 11 prompts. ChatGPT outperformed the other LLMs across all rubric criteria, scoring an overall response score of 3.35 \u00b1 0.42 (83.8%). However, Google Bard excelled in readability, leading in 75% of the metrics assessed. Importantly, no responses were found to pose risks to patients, ensuring the safety and reliability of the information provided.Conclusions:ChatGPT demonstrated superior accuracy and comprehensiveness in responding to cornea-related prompts, whereas Google Bard stood out for its readability. The study highlights the potential of LLMs in streamlining various clinical, administrative, and research tasks in ophthalmology. Future research should incorporate patient feedback and ongoing data collection to monitor LLM performance over time. Despite their promise, LLMs should be used with caution, necessitating continuous oversight by medical professionals and standardized evaluations to ensure patient safety and maximize benefits.",
        "address": "United States",
        "author": "Nichani, Prem A. H. and Ong Tone, Stephan and AlShaker, Sara M. and Teichman, Joshua C. and Chan, Clara C.",
        "copyright": "Copyright \u00a9 2024 Wolters Kluwer Health, Inc. All rights reserved.",
        "issn": "0277-3740",
        "journal": "Cornea",
        "keywords": "large language models ; artificial intelligence ; clinic efficiency ; cornea ; Corneal Diseases - therapy ; Generative Artificial Intelligence ; Humans ; Internet ; Language ; Ophthalmology - education ; patient counselling",
        "language": "eng",
        "number": "6",
        "pages": "788-794",
        "publisher": "Cornea",
        "title": "Use of Online Large Language Model Chatbots in Cornea Clinics",
        "type": "article",
        "volume": "44",
        "year": "2025"
    },
    "PapageorgiouEleftheria2024ASot": {
        "abstract": "The proliferation of fake news and fake profiles on social media platforms poses significant threats to information integrity and societal trust. Traditional detection methods, including rule-based approaches, metadata analysis, and human fact-checking, have been employed to combat disinformation, but these methods often fall short in the face of increasingly sophisticated fake content. This review article explores the emerging role of Large Language Models (LLMs) in enhancing the detection of fake news and fake profiles. We provide a comprehensive overview of the nature and spread of disinformation, followed by an examination of existing detection methodologies. The article delves into the capabilities of LLMs in generating both fake news and fake profiles, highlighting their dual role as both a tool for disinformation and a powerful means of detection. We discuss the various applications of LLMs in text classification, fact-checking, verification, and contextual analysis, demonstrating how these models surpass traditional methods in accuracy and efficiency. Additionally, the article covers LLM-based detection of fake profiles through profile attribute analysis, network analysis, and behavior pattern recognition. Through comparative analysis, we showcase the advantages of LLMs over conventional techniques and present case studies that illustrate practical applications. Despite their potential, LLMs face challenges such as computational demands and ethical concerns, which we discuss in more detail. The review concludes with future directions for research and development in LLM-based fake news and fake profile detection, underscoring the importance of continued innovation to safeguard the authenticity of online information.",
        "address": "BASEL",
        "author": "Papageorgiou, Eleftheria and Chronis, Christos and Varlamis, Iraklis and Himeur, Yassine",
        "copyright": "Copyright 2024 Elsevier B.V., All rights reserved.",
        "issn": "1999-5903",
        "journal": "Future internet",
        "keywords": "Research & development ; Artificial intelligence ; Case studies ; Computer Science ; Computer Science Information Systems ; Disinformation ; fact-checking ; fake news ; fake profiles ; False information ; Large language models ; large language models (LLMs) ; Network analysis ; News ; Pattern analysis ; Pattern recognition ; R&D ; Science & Technology ; Social media ; Social networks ; Technology ; text classification",
        "language": "eng",
        "number": "8",
        "pages": "298-",
        "publisher": "Mdpi",
        "title": "A Survey on the Use of Large Language Models (LLMs) in Fake News",
        "type": "article",
        "volume": "16",
        "year": "2024"
    },
    "WangQ.2022ESTS": {
        "abstract": "Since the inception of electronic health records (EHR) and population health records (PopHR), the volume of archived digital health records is growing rapidly. Large volumes of heterogeneous health records require advanced visualization and visual analytics systems to uncover valuable insight buried in complex databases. As a vibrant sub\u2010field of information visualization and visual analytics, many interactive EHR and PopHR visualization (EHR Vis) systems have been proposed, developed, and evaluated by clinicians to support effective clinical analysis and decision making. We present the state\u2010of\u2010the\u2010art (STAR) of EHR Vis literature and open access healthcare data sources and provide an up\u2010to\u2010date overview on this important topic. We identify trends and challenges in the field, introduce novel literature and data classifications, and incorporate a popular medical terminology standard called the Unified Medical Language System (UMLS). We provide a curated list of electronic and population healthcare data sources and open access datasets as a resource for potential researchers, in order to address one of the main challenges in this field. We classify the literature based on multidisciplinary research themes stemming from reoccurring topics. The survey provides a valuable overview of EHR Vis revealing both mature areas and potential future multidisciplinary research directions. Since the inception of electronic health records (EHR) and population health records (PopHR), the volume of archived digital health records is growing rapidly.",
        "address": "HOBOKEN",
        "author": "Wang, Q. and Laramee, R.S.",
        "copyright": "2021 The Authors. published by Eurographics \u2010 The European Association for Computer Graphics and John Wiley & Sons Ltd",
        "issn": "0167-7055",
        "journal": "Computer graphics forum",
        "keywords": "Computer Science Software Engineering ; visualization ; Computer Science ; Data sources ; Decision analysis ; Decision making ; Electronic health records ; Health care ; information visualization ; interaction ; interaction techniques ; Multidisciplinary research ; Science & Technology ; Scientific visualization ; System effectiveness ; Technology ; visual analytics",
        "language": "eng",
        "number": "1",
        "pages": "69-105",
        "publisher": "Wiley",
        "title": "EHR STAR: The State\u2010Of\u2010the\u2010Art in Interactive EHR Visualization",
        "type": "article",
        "volume": "41",
        "year": "2022"
    },
    "WangQile2025LAPS": {
        "abstract": "Large Language Models (LLMs) have gained attention in research and industry, aiming to streamline processes and enhance text analysis performance. Thematic Analysis (TA), a prevalent qualitative method for analyzing interview content, often requires at least two human experts to review and analyze data. This study demonstrates the feasibility of LLM-Assisted Thematic Analysis (LATA) using GPT-4 and Gemini. Specifically, we conducted semi-structured interviews with 14 researchers to gather insights on their experiences generating and analyzing Online Social Network (OSN) communications datasets. Following Braun and Clarke's six-phase TA framework with an inductive approach, we initially analyzed our interview transcripts with human experts. Subsequently, we iteratively designed prompts to guide LLMs through a similar process. We compare and discuss the manually analyzed outcomes with responses generated by LLMs and achieve a cosine similarity score up to 0.76, demonstrating a promising prospect for LATA. Additionally, the study delves into researchers' experiences navigating the complexities of collecting and analyzing OSN data, offering recommendations for future research and application designers.",
        "address": "New York, NY, USA",
        "author": "Wang, Qile and Erqsous, Moath and Barner, Kenneth E. and Mauriello, Matthew Louis",
        "copyright": "ACM",
        "issn": "2573-0142",
        "journal": "Proceedings of the ACM on human-computer interaction",
        "keywords": "Human computer interaction (HCI) ; Human-centered computing",
        "language": "eng",
        "number": "2",
        "pages": "1-28",
        "publisher": "ACM",
        "title": "LATA: A Pilot Study on LLM-Assisted Thematic Analysis of Online Social Network Data Generation Experiences",
        "type": "article",
        "volume": "9",
        "year": "2025"
    },
    "WatkinsRyan2024Gfra": {
        "abstract": "For researchers interested in exploring the exciting applications of Large Language Models (LLMs) in their scientific investigations, there is currently limited guidance and few norms for them to consult. Similarly, those providing peer-reviews on research articles where LLMs were used are without conventions or standards to apply or guidelines to follow. This situation is understandable given the rapid and recent development of LLMs that are capable of valuable contributions to research workflows (such as OpenAI\u2019s ChatGPT). Nevertheless, now is the time to begin the development of norms, conventions, and standards that can be applied by researchers and peer-reviewers. By applying the principles of Artificial Intelligence (AI) ethics, we can better ensure that the use of LLMs in scientific research aligns with ethical principles and best practices. This editorial hopes to inspire further dialogue and research in this crucial area of scientific investigation.",
        "address": "Cham",
        "author": "Watkins, Ryan",
        "copyright": "The Author(s), under exclusive licence to Springer Nature Switzerland AG 2023",
        "issn": "2730-5953",
        "journal": "Ai and ethics (Online)",
        "keywords": "Ethics ; Artificial Intelligence ; Computer Science ; Opinion Paper",
        "language": "eng",
        "number": "4",
        "pages": "969-974",
        "publisher": "Springer International Publishing",
        "title": "Guidance for researchers and peer-reviewers on the ethical use of Large Language Models (LLMs) in scientific research workflows",
        "type": "article",
        "volume": "4",
        "year": "2024"
    },
    "liu2025visionautoresearchllm": {
        "archiveprefix": "arXiv",
        "author": "Chengwei Liu and Chong Wang and Jiayue Cao and Jingquan Ge and Kun Wang and Lvye Zhang and Ming-Ming Cheng and Penghai Zhao and Tianlin Li and Xiaojun Jia and Xiang Li and Xinfeng Li and Yang Liu and Yebo Feng and Yihao Huang and Yijia Xu and Yuqiang Sun and Zhenhong Zhou and Zhengzi Xu",
        "eprint": "2504.18765",
        "primaryclass": "cs.AI",
        "title": "A Vision for Auto Research with LLM Agents",
        "type": "misc",
        "url": "https://arxiv.org/abs/2504.18765",
        "year": "2025"
    },
    "zheng2023trafficsafetygpttuningpretrainedlarge": {
        "archiveprefix": "arXiv",
        "author": "Ou Zheng and Mohamed Abdel-Aty and Dongdong Wang and Chenzhu Wang and Shengxuan Ding",
        "eprint": "2307.15311",
        "primaryclass": "cs.CL",
        "title": "TrafficSafetyGPT: Tuning a Pre-trained Large Language Model to a Domain-Specific Expert in Transportation Safety",
        "type": "misc",
        "url": "https://arxiv.org/abs/2307.15311",
        "year": "2023"
    }
}});